defaults:
  - hydra: defaults
  - dataset: tweet
  - model/encoder: lstm
  - model/decoder: perceptron
  - loss: [cce]
  - _self_ 

data_loader:
  train:
    num_workers: 16
    persistent_workers: true
    batch_size: 4
    random_seed: 42
  test:
    num_workers: 4
    persistent_workers: false
    batch_size: 1
    random_seed: 42
  val:
    num_workers: 1
    persistent_workers: true
    batch_size: 1
    random_seed: 42

trainer:
  epoch_num: 100
  pretrained_ckpt: null
  optimizer:
    optimizer_type: "adam"
    base_lr: 1.5e-3
    betas:
      - 0.9
      - 0.999
    scheduler: 'cos'
    eta_min: 1e-5
    gradient_clip_val: 0.1
  checkpointing:
    checkpoint_iter: 20
    training_loss_log: 5
    validate_iter: 20
    test_iter: 40