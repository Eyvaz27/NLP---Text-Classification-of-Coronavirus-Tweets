dataset:
  name: tweet
  max_length: 64
  padding: max_length
  truncation: true
  embedding_dim: 768
  class_count: 5
  eval_set_ratio: 0.2
model:
  encoder:
    name: lstm
    input_size: null
    hidden_size: 64
    num_layers: 2
    bias: true
    batch_first: true
    dropout: 0.3
    bidirectional: true
    aggregation: sum
  decoder:
    name: perceptron
    input_size: null
    output_size: null
    non_linearity: null
loss:
  cce:
    name: CCE
    weight: 1.0
data_loader:
  train:
    num_workers: 16
    persistent_workers: true
    batch_size: 4
    random_seed: 42
  test:
    num_workers: 4
    persistent_workers: false
    batch_size: 1
    random_seed: 42
  val:
    num_workers: 1
    persistent_workers: true
    batch_size: 1
    random_seed: 42
trainer:
  epoch_num: 100
  pretrained_ckpt: null
  optimizer:
    optimizer_type: adam
    base_lr: 0.0015
    betas:
    - 0.9
    - 0.999
    scheduler: cos
    eta_min: 1.0e-05
    gradient_clip_val: 0.1
  checkpointing:
    checkpoint_iter: 20
    training_loss_log: 5
    validate_iter: 20
    test_iter: 40
