dataset:
  name: tweet
  max_length: 64
  padding: max_length
  truncation: true
  embedding_dim: 768
  class_count: 5
  eval_set_ratio: 0.2
model:
  encoder:
    name: transformer
    embed_dim: 768
    depth: 2
    num_heads: 12
    mlp_ratio: 4.0
    qkv_bias: true
    ffn_bias: true
    proj_bias: true
    drop_path_rate: 0.0
    drop_path_uniform: false
    use_memory_efficient: false
    init_values: 1.0
  decoder:
    name: perceptron
    input_size: null
    output_size: null
    non_linearity: null
loss:
  cce:
    name: CCE
    weight: 1.0
data_loader:
  train:
    num_workers: 4
    prefetch_factor: 8
    persistent_workers: true
    batch_size: 8
    random_seed: 42
  test:
    num_workers: 1
    prefetch_factor: 1
    persistent_workers: false
    batch_size: 1
    random_seed: 42
  val:
    num_workers: 1
    prefetch_factor: 1
    persistent_workers: true
    batch_size: 1
    random_seed: 42
trainer:
  epoch_num: 21
  pretrained_ckpt: null
  optimizer:
    optimizer_type: adam
    base_lr: 0.0015
    betas:
    - 0.9
    - 0.999
    scheduler: cos
    eta_min: 1.0e-05
    gradient_clip_val: 0.1
  checkpointing:
    checkpoint_iter: 10
    training_loss_log: 1
    validate_iter: 5
    test_iter: 20
